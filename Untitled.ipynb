{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brave-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "racial-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Images/drowsiness.png') # Load input (coffee break) image\n",
    "image = cv2.resize(image, (100,100))          # Resize image to 100x100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "convinced-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sound_alarm(path):\n",
    "\t# play an alarm sound\n",
    "\tplaysound.playsound(path)\n",
    "'''\n",
    "Eye Aspect Ratio (E.A.R.)\n",
    "Function to calculate eye aspect ratio as in paper :\n",
    "\"Real-Time Eye Blink Detection using Facial Landmarks [Soukupova, Cech]\"             \n",
    "Landmarks |   0  1  2  3  4  5\n",
    " Left Eye : [36,37,38,39,40,41]\n",
    "Right Eye : [42,43,44,45,46,47]\n",
    "'''\n",
    "def eye_aspect_ratio(eye):\n",
    "     # Vertical distances\n",
    "     dist1 = dist.euclidean(eye[1], eye[5]) # P2-P6\n",
    "     dist2 = dist.euclidean(eye[2], eye[4]) # P3-P5\n",
    "     # Horiontal distance\n",
    "     dist3 = dist.euclidean(eye[0], eye[3]) # P1-P4\n",
    "\n",
    "     # Eye Aspect Ratio (E.A.R.)\n",
    "     ear = (dist1 + dist2) / (2.0 * dist3)\n",
    "\n",
    "     return ear\n",
    "\n",
    "\n",
    "'''\n",
    "Lips Aspect Ratio (L.A.R.)\n",
    "Function to calculate lips aspect ratio in the same way as in E.A.R.\n",
    "Landmarks |   0  1  2  3  4  5  6  7\n",
    "     Lips : [60,61,62,63,64,65,66,67]\n",
    "'''\n",
    "def lips_aspect_ratio(lips):\n",
    "     # Vertical distance\n",
    "     dist1 = dist.euclidean(lips[2], lips[6]) # L3-L7\n",
    "     # Horiontal distance\n",
    "     dist2 = dist.euclidean(lips[0], lips[4]) # L1-L5\n",
    "\n",
    "     # Lips Aspect Ratio (L.A.R.)\n",
    "     lar = float(dist1/dist2)\n",
    "\n",
    "     return lar\n",
    "\n",
    "\n",
    "'''\n",
    "Facial Landmarks for any face part\n",
    "Function to calculate facial landmark point coordinates (x,y),\n",
    "draw them on frame and return a numpy array with the corresponding points\n",
    "'''\n",
    "def draw_landmarks(face_part, landmarks):\n",
    "     landmarks_list = []\n",
    "     for point in face_part:\n",
    "          x, y = landmarks.part(point).x, landmarks.part(point).y\n",
    "          landmarks_list.append([x,y])\n",
    "          cv2.circle(frame, (x,y), 2, (0,0,255), -1)\n",
    "          \n",
    "     return np.array(landmarks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decimal-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DLIB - Face Detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "# DLIB - Predictor\n",
    "predictor = dlib.shape_predictor('Models/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# Video Capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Text settings\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.7\n",
    "\n",
    "# Initializations\n",
    "frames = 0\n",
    "\n",
    "# ear & lar, threshold values\n",
    "ear_thresh = 0.3\n",
    "lar_thresh = 0.5\n",
    "\n",
    "# Blink initializations\n",
    "blink_counter, total_blinks = 0, 0\n",
    "# Yawn initializations\n",
    "yawn_counter, total_yawns = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "     _, frame = cap.read()\n",
    "     frame = cv2.flip(frame, 1) # May not be necessary\n",
    "     h, w = frame.shape[: 2]    # Height and Width of frame\n",
    "     \n",
    "     frames += 1\n",
    "\n",
    "     # Grayscale\n",
    "     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "     # Detect faces in the gray frame\n",
    "     faces = detector(gray, 0)\n",
    "\n",
    "     # Loop through each face\n",
    "     for face in faces:\n",
    "          # Determine facial landmarks\n",
    "          facial_landmarks = predictor(gray, face)\n",
    "\n",
    "          # Landmark indexes for eyes and lips\n",
    "          left_eye = [36,37,38,39,40,41]\n",
    "          right_eye = [42,43,44,45,46,47]\n",
    "          \n",
    "          lips = [60,61,62,63,64,65,66,67]\n",
    "\n",
    "          # Convert to numpy array the above lists and\n",
    "          # draw the corresponding facial landmark points on frame\n",
    "          left_eye_points = draw_landmarks(left_eye, facial_landmarks)\n",
    "          right_eye_points = draw_landmarks(right_eye, facial_landmarks)\n",
    "\n",
    "          lips_points = draw_landmarks(lips, facial_landmarks)\n",
    "\n",
    "          # Find and draw the convex hulls of left and right eye, and lips\n",
    "          left_eye_hull = cv2.convexHull(left_eye_points)      \n",
    "          cv2.drawContours(frame, [left_eye_hull], -1, (0, 255, 0), 1)\n",
    "          \n",
    "          right_eye_hull = cv2.convexHull(right_eye_points)\n",
    "          cv2.drawContours(frame, [right_eye_hull], -1, (0, 255, 0), 1)\n",
    "\n",
    "          lips_hull = cv2.convexHull(lips_points)\n",
    "          cv2.drawContours(frame, [lips_hull], -1, (0, 255, 0), 1)\n",
    "\n",
    "          # Calculate E.A.R. and L.A.R.\n",
    "          left_ear = eye_aspect_ratio(left_eye_points)    # Left eye aspect ratio\n",
    "          right_ear =  eye_aspect_ratio(right_eye_points) # Right eye aspect ratio\n",
    "          ear = (left_ear + right_ear) / 2.0              # Average eye aspect ratio\n",
    "          cv2.putText(frame, \"E.A.R. : {:.2f}\".format(ear), (10,30), font, font_scale, (0,0,255), 2)\n",
    "\n",
    "          lar = lips_aspect_ratio(lips_points) # Lips aspect ratio\n",
    "          cv2.putText(frame, \"L.A.R. : {:.2f}\".format(lar), (10,90), font, font_scale, (0,0,255), 2)\n",
    "\n",
    "          # Check for blinks or yawns\n",
    "          # BLINK\n",
    "          if ear < ear_thresh:\n",
    "               blink_counter += 1\n",
    "          else:\n",
    "               if blink_counter > 3:\n",
    "                    total_blinks += 1\n",
    "               blink_counter = 0\n",
    "          cv2.putText(frame, \"Blinks: {}\".format(total_blinks), (10, 50), font, font_scale, (0, 0, 255), 2)\n",
    "\n",
    "          # YAWN\n",
    "          if lar > lar_thresh:\n",
    "               yawn_counter += 1\n",
    "          else:\n",
    "               if yawn_counter > 1:\n",
    "                    total_yawns += 1\n",
    "               yawn_counter = 0\n",
    "          cv2.putText(frame, \"Yawns: {}\".format(total_yawns), (10, 110), font, font_scale, (0, 0, 255), 2)\n",
    "          \n",
    "          # Drowsiness Detection\n",
    "          if total_yawns > 2 or total_blinks > 3:\n",
    "                frame[20:120, w-120:w-20] = image\n",
    "                sound_alarm(\"alarm.wav\")\n",
    "                cv2.putText(frame, \"ALERT\", (w-120, 160), font, 1.2, (0, 0, 255), 4)\n",
    "\n",
    "     cv2.imshow('Frame', frame)\n",
    "     key = cv2.waitKey(1)\n",
    "     if key == 27:\n",
    "          break\n",
    "     if key == ord('q'):\n",
    "        exit()\n",
    "            \n",
    "     if key==ord('r') or key==ord('R'):\n",
    "          total_blinks, total_yawns = 0, 0 # Reset calculations by pressing 'r' or 'R' \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-congo",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
